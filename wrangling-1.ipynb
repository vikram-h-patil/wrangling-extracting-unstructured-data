{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Date: 2/09/2018\n",
    "\n",
    "\n",
    "\n",
    "Environment: Python 3.6.1 and Jupyter notebook\n",
    "\n",
    "Libraries used: Main libraries used for assignment:\n",
    "* re (for regular expression, included in Anaconda Python 3.6) \n",
    "* json (for writing json converted files, included in Anaconda Python 3.6) \n",
    "* sys (for finding the system version, included in Anaconda Python 3.6) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction\n",
    "\n",
    "\n",
    "This task explores the steps to extract structured data from an unstructured data source. Using regex pattern, data is extracted from files and read and saved in json and xml files. \n",
    "\n",
    "Logic:\n",
    "1) A regex pattern is created to identify all keys present in resumes   \n",
    "2) Using python indexing, all data between two keys is stored for a key as value.   \n",
    "3) final output is sent to json and xml files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=1, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Reading the resume files assigned to me \n",
    "\n",
    "#### While data is read, it is also cleaned in order to save cleaned data for further processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resume data processed= 32069\n"
     ]
    }
   ],
   "source": [
    "with open('29389690.dat','r') as input_file: \n",
    "    task1_ipfile=input_file.read() #---------------------1\n",
    "    task1_ipfile= re.sub('to:', 'to', task1_ipfile) #---2\n",
    "    task1_ipfile= re.sub('&', 'and', task1_ipfile) #----3\n",
    "    task1_ipfile= re.sub('<', 'less than', task1_ipfile) #-----4\n",
    "    task1_ipfile= re.sub('>', 'greater than', task1_ipfile) #---------5\n",
    "    task1_ipfile=(re.sub(r'(?:\\n|^|_)([A-Za-z]+[\\s_]?[A-Za-z]+)[/]', r'\\n\\1: NA', task1_ipfile)) #--------6\n",
    "    resume = re.split(\"----+\\n\", task1_ipfile)#--------7\n",
    "input_file.close()\n",
    "\n",
    "#Above lines are explained below:\n",
    "#1 - File reading\n",
    "#2 - converting whenever word=to: --> word=to,this is required to fetch the data in correct format\n",
    "#3 - converting whenever word=& --> word=and,this is required to fetch the data in correct format\n",
    "#4 - converting whenever word=< --> word=less than,this is required to fetch the data in correct format\n",
    "#5 - converting whenever word=> --> word=greater than,this is required to fetch the data in correct format\n",
    "#6 - A regex pattern to replace whenever blank value is present against any word to \"NA\"\n",
    "    #Explanation of regex pattern (?:\\n|^|_)([A-Za-z]+[\\s_]?[A-Za-z]+)[/]\n",
    "        #(?:\\n|^|_) --> identiifes a non capturing group, any new line or start of string or starting with underscore\n",
    "        #([A-Za-z]+[\\s_]?[A-Za-z]+) --> A group which matches capital/lower word followed by space/underscore and capital/lower word\n",
    "        #[:/] --> the ending character with / or colon\n",
    "        #when above pattern is matched, it is substituted to NA using re.sub command\n",
    "#7 - each resume is split based on lines --------\n",
    "\n",
    "\n",
    "#Further cleaning of data\n",
    "resume = [x for x in resume if x != ''] #if any blank resume is present, it is discarded\n",
    "print(\"Total resume data processed=\",len(resume))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Defining Function to perform set of actions\n",
    "\n",
    "#### 4-1) divide_sub_pattern function is created to divide sentences inside each file whenever semicolon is met. This is required to store  in json and xml format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When semicolon is met, sentences are divided. This is required for creating sub tags for json and xml files.\n",
    "def divide_sub_pattern(data):\n",
    "    data=data.split(';')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2) create_sub_element function is required to create a sub-key for each matched key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For qualification, procedure, description and responsibility we need to divide the values into sub division,\n",
    "#below function will perform, it divides the key into sub-key and further assigns the value to it.\n",
    "def create_sub_element(key,value):\n",
    "    key=re.sub('\\s+', '_',key.lower())\n",
    "    if \"qual\" in key:\n",
    "        data1={\"qualification\":value}\n",
    "    elif \"proc\" in key:\n",
    "        data1={\"procedure\":value}\n",
    "    elif \"desc\" in key :\n",
    "        data1={\"description\":value}\n",
    "    elif \"resp\" in key:\n",
    "        data1={\"responsibility\":value}\n",
    "    else: \n",
    "        data1=key\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3) A function to extracts first, each resume data in dictionary format and pre-process the data in desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_key_value(resume_keys,resume_index):\n",
    "    key=[] #----------------------------------------------list which will store keys.\n",
    "    value=[] #list which will store values with respect to keys.    \n",
    "    for item in range(len(resume_keys)): # to iterate over keys to fetch respective values\n",
    "        name_of_key = resume_keys[item] #stores the name of key passed\n",
    "        \n",
    "#Logic is to find starting and ending position of all keys and then fetch value between two keys. \n",
    "\n",
    "        end_char=(re.search(resume_keys[item], resume_index).end()+1) #ending position of a key\n",
    "        if item+1 <len(resume_keys): \n",
    "            start_char=(re.search(resume_keys[item+1], resume_index).start()-1) #starting position of next consecutive key\n",
    "            value_of_key= resume_index [end_char:start_char] # fetches value between 1st and 2nd key; whcih is output of 1st key\n",
    "            \n",
    "            #data cleaning steps\n",
    "            value_of_key=value_of_key.replace('\\n',' ') #replaces backslash with space\n",
    "            value_of_key = re.sub('\\s+', ' ', value_of_key) #replaces multiple spaces with single space.\n",
    "            \n",
    "            #Next step is to create child key-value pair, only if values contains multiple lines.\n",
    "            if \" - \" in value_of_key : #if any value starts with multiple steps, perform below actions\n",
    "                value_of_key=value_of_key.replace(' - ','') # replace hypen with space\n",
    "                value_of_key=divide_sub_pattern(str(value_of_key)) # calls fucntions which splits strings by ; \n",
    "                value_of_key=create_sub_element(name_of_key,value_of_key) #creation of child-name and value\n",
    "            else :\n",
    "                value_of_key=value_of_key  \n",
    "                value_of_key=value_of_key.lstrip() #removes leading spaces if any\n",
    "                \n",
    "        #This part is to extract only for last key for each resume.\n",
    "        else:\n",
    "            start_char=(re.search(resume_keys[item], resume_index).start()-1)\n",
    "            value_of_key= resume_index [end_char:len(resume_index)] #ending position of last key till end of file.\n",
    "            \n",
    "            #rest of steps are same of above\n",
    "            value_of_key=value_of_key.replace('\\n',' ')\n",
    "            value_of_key = re.sub('\\s+', ' ', value_of_key)\n",
    "            if \" - \" in value_of_key :\n",
    "                value_of_key=value_of_key.replace(' - ','')\n",
    "                value_of_key=divide_sub_pattern(str(value_of_key))\n",
    "                value_of_key=create_sub_element(name_of_key,value_of_key)\n",
    "            else :\n",
    "                value_of_key=value_of_key\n",
    "                value_of_key=value_of_key.lstrip()\n",
    "        key.append(re.sub('\\s+', '_',name_of_key.lower()))  # replace underscore b/w two words if missing and capitalize\n",
    "        value.append(value_of_key)\n",
    "    new_dict= dict(zip(key,value)) #zipping all keys and values to form a dicitonary\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Creates new list, which will contain cleaned resumes.\n",
    "\n",
    "Logic: identify keys by a regex pattern and calls function(extract_key_value) to extract all values for respective keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resume_dict=[]\n",
    "for item in range(len(resume)):\n",
    "    pat_key=r'(?:\\n|^|_)([A-Za-z]+[\\s_]?[A-Za-z]+)[:/]'\n",
    "    pat=re.findall(pat_key,resume[item]) #store each regex matched and output will be keys for each resumes.\n",
    "    resume_dict.append(extract_key_value(pat,resume[item])) #resume_dict stores all resumes in list format.\n",
    "    \n",
    "# regex explanation:(?:\\n|^|_)([A-Za-z]+[\\s_]?[A-Za-z]+)[:/]\n",
    "    #(?:\\n|^|_) --> identiifes a non capturing group, any new line or start of string or starting with underscore\n",
    "    #([A-Za-z]+[\\s_]?[A-Za-z]+) --> A group which matches capital/lower word followed by space/underscore and capital/lower word\n",
    "    #[:/] --> the ending character with / or colon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "### 6) Writing output to files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1) Output to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('29389690.json', 'w') as f:\n",
    "    listing={} #first creare a root node \n",
    "    listing['listing']=resume_dict # add a new key to dictionary. \n",
    "    f.write(json.dumps({'listings': (listings)},indent=4)+\"\\n\\n\\n\\n\\n\") # add final output\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2) Ouput to xml file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a function to write a xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recursive function to create parent and child tags\n",
    "'''\n",
    "l= if value in key value pair is of type string than it will create tags and hold its value \n",
    "l2= if value in key value pair is of type list than it will create child tags \n",
    "l3= holds closing tag name if value in key, value pair is dictionary type\n",
    "lr= final output string contaings all resume data in xml format\n",
    "'''\n",
    "def file2xml(D, l=\"\",l2=\"\",l3=\"\",lr=''): #\n",
    "    if type(D) == dict: \n",
    "        for key, value in D.items():\n",
    "            lr=lr\n",
    "            if isinstance(value, dict):\n",
    "                l3=\"</\"+key+\">\"\n",
    "                lr+=\"<\"+key+\">\"+file2xml(value)+l3                             \n",
    "            elif isinstance(value, tuple) or isinstance(value, list):\n",
    "                for i in range(len(value)):\n",
    "                    val=''.join(value[i])\n",
    "                    l2=\"<\"+key+\">\"+val+\"</\"+key+\">\"\n",
    "                    lr+=l2\n",
    "                lr+=l3\n",
    "            else:\n",
    "                l=\"<\"+key+\">\"+str(value)+\"</\"+key+\">\"\n",
    "                lr+=l    \n",
    "    else :\n",
    "        l+=str(D)+l3\n",
    "        lr+=l\n",
    "    return lr\n",
    "\n",
    "\n",
    "\n",
    "xml_file=[]  #create blank list to store final output for xml\n",
    "# for loop to iterate over each resume and convert it into xml format\n",
    "for item in range(len(resume)):    \n",
    "        xml_file.append(\"<listing>\"+file2xml(resume_dict[item])+\"</listing>\") \n",
    "        # make listing as a parent nood for each resume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writing final output to xml file\n",
    "\n",
    "with open('29389690.xml', 'w') as f:\n",
    "        f.write(\"<listings>\"+''.join(xml_file)+\"</listings>\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
